{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.loggers as pl_loggers\n",
    "from torchvision import models\n",
    "import copy\n",
    "import tltorch\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 4\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "# reproducibility\n",
    "pl.seed_everything(42)\n",
    "# allow tf32 (TENSOR CORES)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True  # allow tf32 on cudnn\n",
    "torch.backends.cudnn.deterministic = True  # deterministic cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/usainzg/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer3.0.conv1', 'layer3.0.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.1.conv1', 'layer4.1.conv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_layer(\n",
    "    module,\n",
    "    factorization='tucker',\n",
    "    rank=None,\n",
    "    decompose_weights=False,\n",
    "    vbmf=0,\n",
    "    implementation='reconstructed'\n",
    "):\n",
    "    init_std = None if decompose_weights else 0.01\n",
    "    decomposition_kwargs = {'init': 'random'} if factorization == 'cp' else {}\n",
    "    fixed_rank_modes = 'spatial' if factorization == 'tucker' else None\n",
    "    # implementation see: https://github.com/tensorly/torch/blob/d27d58f16101b7ecc431372eb218ceda59d8b043/tltorch/functional/convolution.py#L286\n",
    "    \n",
    "    if rank is None and vbmf == 0 and factorization != 'tucker':\n",
    "        raise ValueError('rank must be specified for non-tucker factorization')\n",
    "    \n",
    "    if not decompose_weights:\n",
    "        vbmf = 0 \n",
    "\n",
    "    if type(module) == torch.nn.modules.conv.Conv2d:\n",
    "        # rank selection\n",
    "        \n",
    "        if rank is not None:\n",
    "            ranks = rank\n",
    "        else:\n",
    "            weights = module.weight.data\n",
    "            ranks = [weights.shape[0]//3, weights.shape[1]//3, weights.shape[2], weights.shape[3]]\n",
    "        \n",
    "        # factorize from conv layer\n",
    "        fact_module = tltorch.FactorizedConv.from_conv(\n",
    "            module,\n",
    "            rank=ranks,\n",
    "            decompose_weights=decompose_weights,\n",
    "            factorization=factorization,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            implementation=implementation,\n",
    "            decomposition_kwargs=decomposition_kwargs\n",
    "        )\n",
    "    elif type(module) == torch.nn.modules.linear.Linear:\n",
    "        fact_module = tltorch.FactorizedLinear.from_linear(\n",
    "            module,\n",
    "            n_tensorized_modes=3,\n",
    "            rank=rank,\n",
    "            factorization=factorization,\n",
    "            decompose_weights=decompose_weights,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            decomposition_kwargs=decomposition_kwargs\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(type(module))\n",
    "    \n",
    "    if init_std:\n",
    "        #print('Initializing with std')\n",
    "        fact_module.weight.normal_(0, init_std)\n",
    "    \n",
    "    return fact_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorizing: layer1.0.conv1\n",
      "factorizing: layer1.0.conv2\n",
      "factorizing: layer1.1.conv1\n",
      "factorizing: layer1.1.conv2\n",
      "factorizing: layer2.0.conv1\n",
      "factorizing: layer2.0.conv2\n",
      "factorizing: layer2.1.conv1\n",
      "factorizing: layer2.1.conv2\n",
      "factorizing: layer3.0.conv1\n",
      "factorizing: layer3.0.conv2\n",
      "factorizing: layer3.1.conv1\n",
      "factorizing: layer3.1.conv2\n"
     ]
    }
   ],
   "source": [
    "fact_model = copy.deepcopy(model)\n",
    "tn_decomp = 'tucker'\n",
    "rank = 0.8\n",
    "vbmf = 0\n",
    "decompose_weights = True\n",
    "implementation = 'reconstructed'\n",
    "\n",
    "# factorize resnet\n",
    "for i, (name, module) in enumerate(model.named_modules()):\n",
    "    if name in layer_names:\n",
    "        \n",
    "        print(f'factorizing: {name}')\n",
    "        fact_module = factorize_layer(\n",
    "            module=module, \n",
    "            factorization=tn_decomp, \n",
    "            rank=rank, \n",
    "            vbmf=vbmf,\n",
    "            decompose_weights=decompose_weights,\n",
    "            implementation=implementation\n",
    "        )\n",
    "        layer, block, conv = name.split('.')\n",
    "        conv_to_replace = getattr(getattr(fact_model, layer), block)\n",
    "        setattr(conv_to_replace, conv, fact_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CifarResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=16, out_channels=16, kernel_size=(3, 3), rank=(13, 13, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(16, 16, 3, 3), rank=(13, 13, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=16, out_channels=16, kernel_size=(3, 3), rank=(13, 13, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(16, 16, 3, 3), rank=(13, 13, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=16, out_channels=16, kernel_size=(3, 3), rank=(13, 13, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(16, 16, 3, 3), rank=(13, 13, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=16, out_channels=16, kernel_size=(3, 3), rank=(13, 13, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(16, 16, 3, 3), rank=(13, 13, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=16, out_channels=32, kernel_size=(3, 3), rank=(24, 12, 3, 3), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(32, 16, 3, 3), rank=(24, 12, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=32, out_channels=32, kernel_size=(3, 3), rank=(25, 25, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(32, 32, 3, 3), rank=(25, 25, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=32, out_channels=32, kernel_size=(3, 3), rank=(25, 25, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(32, 32, 3, 3), rank=(25, 25, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=32, out_channels=32, kernel_size=(3, 3), rank=(25, 25, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(32, 32, 3, 3), rank=(25, 25, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=32, out_channels=64, kernel_size=(3, 3), rank=(49, 25, 3, 3), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 32, 3, 3), rank=(49, 25, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12 ms ± 62.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.61 ms ± 171 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fact_model(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdcomp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

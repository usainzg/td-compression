{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from tltorch import FactorizedConv\n",
    "import tltorch\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_params(net: torch.nn.Module) -> np.array:\n",
    "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param = count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorizing: layer1.0.conv1\n",
      "factorizing: layer1.0.conv2\n",
      "factorizing: layer1.1.conv1\n",
      "factorizing: layer1.1.conv2\n",
      "factorizing: layer2.0.conv1\n",
      "factorizing: layer2.0.conv2\n",
      "factorizing: layer2.1.conv1\n",
      "factorizing: layer2.1.conv2\n",
      "factorizing: layer3.0.conv1\n",
      "factorizing: layer3.0.conv2\n",
      "factorizing: layer3.1.conv1\n",
      "factorizing: layer3.1.conv2\n",
      "factorizing: layer4.0.conv1\n",
      "factorizing: layer4.0.conv2\n",
      "factorizing: layer4.1.conv1\n",
      "factorizing: layer4.1.conv2\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "factorization = 'tucker'\n",
    "rank = 0.8\n",
    "decompose_weights = True\n",
    "td_init = not decompose_weights\n",
    "\n",
    "decomposition_kwargs = {'init': 'random'} if factorization == 'cp' else {}\n",
    "fixed_rank_modes = 'spatial' if factorization == 'tucker' else None\n",
    "\n",
    "fact_model = copy.deepcopy(model)\n",
    "\n",
    "ranks = {\n",
    "    'layer1.0.conv1': (64, 16),\n",
    "    'layer1.0.conv2': (64, 16),\n",
    "    'layer1.1.conv1': (64, 16),\n",
    "    'layer1.1.conv2': (64, 16),\n",
    "    'layer2.0.conv1': (128, 16),\n",
    "    'layer2.0.conv2': (128, 16),\n",
    "    'layer2.1.conv1': (128, 16),\n",
    "    'layer2.1.conv2': (128, 16),\n",
    "    'layer3.0.conv1': (256, 16),\n",
    "    'layer3.0.conv2': (256, 16),\n",
    "    'layer3.1.conv1': (256, 16),\n",
    "    'layer3.1.conv2': (256, 16),\n",
    "    'layer4.0.conv1': (512, 16),\n",
    "    'layer4.0.conv2': (512, 16),\n",
    "    'layer4.1.conv1': (512, 16),\n",
    "    'layer4.1.conv2': (512, 16),\n",
    "}\n",
    "\n",
    "layer_names = list(ranks.keys())\n",
    "\n",
    "for i, (name, module) in enumerate(model.named_modules()):\n",
    "    if name in layer_names:\n",
    "        print(f'factorizing: {name}')\n",
    "        if type(module) == torch.nn.modules.conv.Conv2d:\n",
    "            fact_layer = tltorch.FactorizedConv.from_conv(\n",
    "                module, \n",
    "                rank=rank, \n",
    "                decompose_weights=decompose_weights, \n",
    "                factorization=factorization,\n",
    "                fixed_rank_modes=fixed_rank_modes,\n",
    "                decomposition_kwargs=decomposition_kwargs,\n",
    "            )\n",
    "            if td_init:\n",
    "                fact_layer.weight.normal_(0, td_init)\n",
    "            layer, block, conv = name.split('.')\n",
    "            conv_to_replace = getattr(getattr(fact_model, layer), block)\n",
    "            setattr(conv_to_replace, conv, fact_layer)\n",
    "            \n",
    "n_param_fact = count_params(fact_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number of parameters: 11689512\n",
      "factorized number of parameters: 9501963\n",
      "before - after: 2187549\n",
      "compression ratio: 1.23\n"
     ]
    }
   ],
   "source": [
    "print(f'original number of parameters: {n_param}')\n",
    "print(f'factorized number of parameters: {n_param_fact}')\n",
    "print(f'before - after: {n_param - n_param_fact}')\n",
    "print(f'compression ratio: {n_param / n_param_fact:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(54, 54, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(54, 54, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=64, out_channels=64, kernel_size=(3, 3), rank=(51, 51, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(64, 64, 3, 3), rank=(51, 51, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=64, out_channels=128, kernel_size=(3, 3), rank=(98, 49, 3, 3), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 64, 3, 3), rank=(98, 49, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(101, 101, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(101, 101, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(101, 101, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(101, 101, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=128, out_channels=128, kernel_size=(3, 3), rank=(101, 101, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(128, 128, 3, 3), rank=(101, 101, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=128, out_channels=256, kernel_size=(3, 3), rank=(196, 98, 3, 3), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 128, 3, 3), rank=(196, 98, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(202, 202, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(202, 202, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(202, 202, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(202, 202, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=256, out_channels=256, kernel_size=(3, 3), rank=(202, 202, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(256, 256, 3, 3), rank=(202, 202, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=256, out_channels=512, kernel_size=(3, 3), rank=(392, 196, 3, 3), order=2, stride=[2, 2], padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 256, 3, 3), rank=(392, 196, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(405, 405, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(405, 405, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(405, 405, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(405, 405, 3, 3))\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): FactorizedConv(\n",
       "        in_channels=512, out_channels=512, kernel_size=(3, 3), rank=(405, 405, 3, 3), order=2, padding=[1, 1], bias=False\n",
       "        (weight): TuckerTensor(shape=(512, 512, 3, 3), rank=(405, 405, 3, 3))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdcomp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
